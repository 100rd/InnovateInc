# ============================================================================
# Terraform Configuration and Backend
# ============================================================================

terraform {
  # S3 backend with native locking (Terraform 1.5+)
  backend "s3" {
    bucket  = "opsfleet-terraform-state-007027391583"
    key     = "terraform.tfstate"
    region  = "eu-central-1"
    encrypt = true
  }

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 6.22"
    }
    helm = {
      source  = "hashicorp/helm"
      version = "~> 2.10"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
    kubectl = {
      source  = "gavinbunney/kubectl"
      version = "~> 1.14"
    }
  }

  required_version = "~> 1.5"
}

# ============================================================================
# AWS Provider Configuration
# ============================================================================

provider "aws" {
  region = var.region

  default_tags {
    tags = local.common_tags
  }
}

# ============================================================================
# EKS Cluster Data Sources
# ============================================================================

# These data sources are only used after the cluster is created
# to configure kubernetes/helm/kubectl providers

# Note: These data sources will fail on first apply (which is expected)
# After EKS cluster is created, subsequent applies will work
data "aws_eks_cluster" "cluster" {
  name = module.eks.cluster_name

  depends_on = [module.eks]
}

data "aws_eks_cluster_auth" "cluster" {
  name = module.eks.cluster_name

  depends_on = [module.eks]
}

# ============================================================================
# Kubernetes/Helm/Kubectl Provider Configuration
# ============================================================================

# These providers are configured conditionally to avoid circular dependencies
# On first apply, they won't be configured (cluster doesn't exist yet)
# On subsequent applies, they'll use the cluster endpoint

provider "kubernetes" {
  host                   = try(data.aws_eks_cluster.cluster.endpoint, "")
  cluster_ca_certificate = try(base64decode(data.aws_eks_cluster.cluster.certificate_authority[0].data), "")
  token                  = try(data.aws_eks_cluster_auth.cluster.token, "")

  # Only execute commands if cluster exists
  exec {
    api_version = "client.authentication.k8s.io/v1beta1"
    command     = "aws"
    args = [
      "eks",
      "get-token",
      "--cluster-name",
      try(module.eks.cluster_name, "")
    ]
  }
}

provider "helm" {
  kubernetes {
    host                   = try(data.aws_eks_cluster.cluster.endpoint, "")
    cluster_ca_certificate = try(base64decode(data.aws_eks_cluster.cluster.certificate_authority[0].data), "")
    token                  = try(data.aws_eks_cluster_auth.cluster.token, "")

    exec {
      api_version = "client.authentication.k8s.io/v1beta1"
      command     = "aws"
      args = [
        "eks",
        "get-token",
        "--cluster-name",
        try(module.eks.cluster_name, "")
      ]
    }
  }
}

provider "kubectl" {
  host                   = try(data.aws_eks_cluster.cluster.endpoint, "")
  cluster_ca_certificate = try(base64decode(data.aws_eks_cluster.cluster.certificate_authority[0].data), "")
  token                  = try(data.aws_eks_cluster_auth.cluster.token, "")
  load_config_file       = false

  exec {
    api_version = "client.authentication.k8s.io/v1beta1"
    command     = "aws"
    args = [
      "eks",
      "get-token",
      "--cluster-name",
      try(module.eks.cluster_name, "")
    ]
  }
}
